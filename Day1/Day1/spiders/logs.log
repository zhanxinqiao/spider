2021-11-21 13:52:51 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 13:52:51 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 13:52:51 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 13:52:51 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders']}
2021-11-21 13:52:51 [scrapy.extensions.telnet] INFO: Telnet Password: c0878e3059452378
2021-11-21 13:52:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 13:52:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 13:52:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 13:52:52 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2021-11-21 13:52:52 [scrapy.core.engine] INFO: Spider opened
2021-11-21 13:52:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 13:52:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 13:52:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.baidu.com/> (referer: None)
2021-11-21 13:52:52 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 13:52:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 213,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 1476,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.241709,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 5, 52, 52, 355985),
 'httpcompression/response_bytes': 2381,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2021, 11, 21, 5, 52, 52, 114276)}
2021-11-21 13:52:52 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 13:54:30 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 13:54:30 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 13:54:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 13:54:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders']}
2021-11-21 13:54:30 [scrapy.extensions.telnet] INFO: Telnet Password: 9eccde0173b95f2c
2021-11-21 13:54:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 13:54:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 13:54:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 13:54:31 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2021-11-21 13:54:31 [scrapy.core.engine] INFO: Spider opened
2021-11-21 13:54:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 13:54:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 13:54:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.baidu.com/> (referer: None)
2021-11-21 13:54:31 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 13:54:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 213,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 1476,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.16485,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 5, 54, 31, 277423),
 'httpcompression/response_bytes': 2381,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2021, 11, 21, 5, 54, 31, 112573)}
2021-11-21 13:54:31 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 14:07:12 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 14:07:12 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 14:07:12 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 14:07:12 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 3,
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders'],
 'USER_AGENT': 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 '
               'Safari/537.36'}
2021-11-21 14:07:12 [scrapy.extensions.telnet] INFO: Telnet Password: a66c87618546afca
2021-11-21 14:07:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 14:07:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 14:07:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 14:07:13 [scrapy.middleware] INFO: Enabled item pipelines:
['Day1.pipelines.Day1Pipeline']
2021-11-21 14:07:13 [scrapy.core.engine] INFO: Spider opened
2021-11-21 14:07:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 14:07:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 14:07:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.baidu.com/> from <GET http://www.baidu.com/>
2021-11-21 14:07:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baidu.com/> (referer: None)
2021-11-21 14:07:18 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 14:07:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 610,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 84445,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 4.85637,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 6, 7, 18, 115624),
 'httpcompression/response_bytes': 326161,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 2,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2021, 11, 21, 6, 7, 13, 259254)}
2021-11-21 14:07:18 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 14:07:34 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 14:07:34 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 14:07:34 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 14:07:34 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 3,
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders'],
 'USER_AGENT': 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 '
               'Safari/537.36'}
2021-11-21 14:07:34 [scrapy.extensions.telnet] INFO: Telnet Password: d215a820791647da
2021-11-21 14:07:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 14:07:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 14:07:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 14:07:34 [scrapy.middleware] INFO: Enabled item pipelines:
['Day1.pipelines.Day1Pipeline']
2021-11-21 14:07:34 [scrapy.core.engine] INFO: Spider opened
2021-11-21 14:07:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 14:07:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 14:07:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.baidu.com/> from <GET http://www.baidu.com/>
2021-11-21 14:07:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baidu.com/> (referer: None)
2021-11-21 14:07:37 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 14:07:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 610,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 84410,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 2.822769,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 6, 7, 37, 659234),
 'httpcompression/response_bytes': 326100,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 2,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2021, 11, 21, 6, 7, 34, 836465)}
2021-11-21 14:07:37 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 14:09:19 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 14:09:19 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 14:09:19 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 14:09:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 3,
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders'],
 'USER_AGENT': 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 '
               'Safari/537.36'}
2021-11-21 14:09:19 [scrapy.extensions.telnet] INFO: Telnet Password: 1e69ebec2ffacb90
2021-11-21 14:09:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 14:09:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 14:09:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 14:09:20 [scrapy.middleware] INFO: Enabled item pipelines:
['Day1.pipelines.Day1Pipeline']
2021-11-21 14:09:20 [scrapy.core.engine] INFO: Spider opened
2021-11-21 14:09:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 14:09:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 14:09:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.baidu.com/> from <GET http://www.baidu.com/>
2021-11-21 14:09:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baidu.com/> (referer: None)
2021-11-21 14:09:25 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 14:09:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 610,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 84398,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 4.820143,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 6, 9, 25, 195157),
 'httpcompression/response_bytes': 326118,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 2,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2021, 11, 21, 6, 9, 20, 375014)}
2021-11-21 14:09:25 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 14:10:01 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 14:10:01 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 14:10:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 14:10:01 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 3,
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders'],
 'USER_AGENT': 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 '
               'Safari/537.36'}
2021-11-21 14:10:01 [scrapy.extensions.telnet] INFO: Telnet Password: d0a03e0c0865345c
2021-11-21 14:10:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 14:10:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 14:10:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 14:10:02 [scrapy.middleware] INFO: Enabled item pipelines:
['Day1.pipelines.Day1Pipeline']
2021-11-21 14:10:02 [scrapy.core.engine] INFO: Spider opened
2021-11-21 14:10:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 14:10:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 14:10:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baidu.com/> (referer: None)
2021-11-21 14:10:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.baidu.com/> (referer: None)
Traceback (most recent call last):
  File "F:\Kernel\python\python3.9.9\lib\site-packages\twisted\internet\defer.py", line 858, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "F:\Kernel\python\python3.9.9\lib\site-packages\scrapy\spiders\__init__.py", line 90, in _parse
    return self.parse(response, **kwargs)
  File "F:\PyCharm\PyCharmProject\Reptile\Day1\Day1\spiders\baidu.py", line 18, in parse
    print(name+"的链接是"+src)
TypeError: can only concatenate list (not "str") to list
2021-11-21 14:10:02 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 14:10:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 305,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 83103,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.50558,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 6, 10, 2, 781572),
 'httpcompression/response_bytes': 326088,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2021, 11, 21, 6, 10, 2, 275992)}
2021-11-21 14:10:02 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 14:10:18 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 14:10:18 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 14:10:18 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 14:10:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 3,
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders'],
 'USER_AGENT': 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 '
               'Safari/537.36'}
2021-11-21 14:10:18 [scrapy.extensions.telnet] INFO: Telnet Password: 0b5b6b59faa3e5f5
2021-11-21 14:10:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 14:10:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 14:10:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 14:10:19 [scrapy.middleware] INFO: Enabled item pipelines:
['Day1.pipelines.Day1Pipeline']
2021-11-21 14:10:19 [scrapy.core.engine] INFO: Spider opened
2021-11-21 14:10:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 14:10:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 14:10:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baidu.com/> (referer: None)
2021-11-21 14:10:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.baidu.com/> (referer: None)
Traceback (most recent call last):
  File "F:\Kernel\python\python3.9.9\lib\site-packages\parsel\selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src\lxml\etree.pyx", line 1582, in lxml.etree._Element.xpath
  File "src\lxml\xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src\lxml\xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Kernel\python\python3.9.9\lib\site-packages\twisted\internet\defer.py", line 858, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "F:\Kernel\python\python3.9.9\lib\site-packages\scrapy\spiders\__init__.py", line 90, in _parse
    return self.parse(response, **kwargs)
  File "F:\PyCharm\PyCharmProject\Reptile\Day1\Day1\spiders\baidu.py", line 14, in parse
    li_list=response.xpath('//div[@id="s-top-left"]/')
  File "F:\Kernel\python\python3.9.9\lib\site-packages\scrapy\http\response\text.py", line 139, in xpath
    return self.selector.xpath(query, **kwargs)
  File "F:\Kernel\python\python3.9.9\lib\site-packages\parsel\selector.py", line 260, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "F:\Kernel\python\python3.9.9\lib\site-packages\six.py", line 718, in reraise
    raise value.with_traceback(tb)
  File "F:\Kernel\python\python3.9.9\lib\site-packages\parsel\selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src\lxml\etree.pyx", line 1582, in lxml.etree._Element.xpath
  File "src\lxml\xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src\lxml\xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[@id="s-top-left"]/
2021-11-21 14:10:19 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 14:10:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 305,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 83297,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.624022,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 6, 10, 19, 687439),
 'httpcompression/response_bytes': 326151,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2021, 11, 21, 6, 10, 19, 63417)}
2021-11-21 14:10:19 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 14:10:41 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 14:10:41 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 14:10:41 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 14:10:41 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 3,
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders'],
 'USER_AGENT': 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 '
               'Safari/537.36'}
2021-11-21 14:10:41 [scrapy.extensions.telnet] INFO: Telnet Password: 16046633f7692788
2021-11-21 14:10:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 14:10:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 14:10:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 14:10:42 [scrapy.middleware] INFO: Enabled item pipelines:
['Day1.pipelines.Day1Pipeline']
2021-11-21 14:10:42 [scrapy.core.engine] INFO: Spider opened
2021-11-21 14:10:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 14:10:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 14:10:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baidu.com/> (referer: None)
2021-11-21 14:10:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.baidu.com/> (referer: None)
Traceback (most recent call last):
  File "F:\Kernel\python\python3.9.9\lib\site-packages\parsel\selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src\lxml\etree.pyx", line 1582, in lxml.etree._Element.xpath
  File "src\lxml\xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src\lxml\xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Kernel\python\python3.9.9\lib\site-packages\twisted\internet\defer.py", line 858, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "F:\Kernel\python\python3.9.9\lib\site-packages\scrapy\spiders\__init__.py", line 90, in _parse
    return self.parse(response, **kwargs)
  File "F:\PyCharm\PyCharmProject\Reptile\Day1\Day1\spiders\baidu.py", line 14, in parse
    li_list=response.xpath('//div[@id="s-top-left"]/').extract()
  File "F:\Kernel\python\python3.9.9\lib\site-packages\scrapy\http\response\text.py", line 139, in xpath
    return self.selector.xpath(query, **kwargs)
  File "F:\Kernel\python\python3.9.9\lib\site-packages\parsel\selector.py", line 260, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "F:\Kernel\python\python3.9.9\lib\site-packages\six.py", line 718, in reraise
    raise value.with_traceback(tb)
  File "F:\Kernel\python\python3.9.9\lib\site-packages\parsel\selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src\lxml\etree.pyx", line 1582, in lxml.etree._Element.xpath
  File "src\lxml\xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src\lxml\xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[@id="s-top-left"]/
2021-11-21 14:10:43 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 14:10:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 305,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 83106,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.564784,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 6, 10, 43, 79228),
 'httpcompression/response_bytes': 326101,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2021, 11, 21, 6, 10, 42, 514444)}
2021-11-21 14:10:43 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 14:11:03 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 14:11:03 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 14:11:03 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 14:11:03 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 3,
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders'],
 'USER_AGENT': 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 '
               'Safari/537.36'}
2021-11-21 14:11:03 [scrapy.extensions.telnet] INFO: Telnet Password: 2957b1349b7c995c
2021-11-21 14:11:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 14:11:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 14:11:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 14:11:03 [scrapy.middleware] INFO: Enabled item pipelines:
['Day1.pipelines.Day1Pipeline']
2021-11-21 14:11:03 [scrapy.core.engine] INFO: Spider opened
2021-11-21 14:11:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 14:11:03 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 14:11:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baidu.com/> (referer: None)
2021-11-21 14:11:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.baidu.com/> (referer: None)
Traceback (most recent call last):
  File "F:\Kernel\python\python3.9.9\lib\site-packages\parsel\selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src\lxml\etree.pyx", line 1582, in lxml.etree._Element.xpath
  File "src\lxml\xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src\lxml\xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Kernel\python\python3.9.9\lib\site-packages\twisted\internet\defer.py", line 858, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "F:\Kernel\python\python3.9.9\lib\site-packages\scrapy\spiders\__init__.py", line 90, in _parse
    return self.parse(response, **kwargs)
  File "F:\PyCharm\PyCharmProject\Reptile\Day1\Day1\spiders\baidu.py", line 14, in parse
    li_list=response.xpath('//div[@id="s-top-left"]/').extract()
  File "F:\Kernel\python\python3.9.9\lib\site-packages\scrapy\http\response\text.py", line 139, in xpath
    return self.selector.xpath(query, **kwargs)
  File "F:\Kernel\python\python3.9.9\lib\site-packages\parsel\selector.py", line 260, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "F:\Kernel\python\python3.9.9\lib\site-packages\six.py", line 718, in reraise
    raise value.with_traceback(tb)
  File "F:\Kernel\python\python3.9.9\lib\site-packages\parsel\selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src\lxml\etree.pyx", line 1582, in lxml.etree._Element.xpath
  File "src\lxml\xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src\lxml\xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[@id="s-top-left"]/
2021-11-21 14:11:04 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 14:11:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 305,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 83270,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.529482,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 6, 11, 4, 343938),
 'httpcompression/response_bytes': 326081,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2021, 11, 21, 6, 11, 3, 814456)}
2021-11-21 14:11:04 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 14:11:55 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 14:11:55 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 14:11:55 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 14:11:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 3,
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders'],
 'USER_AGENT': 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 '
               'Safari/537.36'}
2021-11-21 14:11:55 [scrapy.extensions.telnet] INFO: Telnet Password: 1e437026c276b7fa
2021-11-21 14:11:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 14:11:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 14:11:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 14:11:55 [scrapy.middleware] INFO: Enabled item pipelines:
['Day1.pipelines.Day1Pipeline']
2021-11-21 14:11:55 [scrapy.core.engine] INFO: Spider opened
2021-11-21 14:11:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 14:11:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 14:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baidu.com/> (referer: None)
2021-11-21 14:11:56 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 14:11:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 305,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 83108,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.455128,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 6, 11, 56, 410781),
 'httpcompression/response_bytes': 326116,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2021, 11, 21, 6, 11, 55, 955653)}
2021-11-21 14:11:56 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 14:13:04 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 14:13:04 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 14:13:04 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 14:13:04 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 3,
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders'],
 'USER_AGENT': 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 '
               'Safari/537.36'}
2021-11-21 14:13:04 [scrapy.extensions.telnet] INFO: Telnet Password: 64dccf2e47932d0f
2021-11-21 14:13:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 14:13:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 14:13:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 14:13:05 [scrapy.middleware] INFO: Enabled item pipelines:
['Day1.pipelines.Day1Pipeline']
2021-11-21 14:13:05 [scrapy.core.engine] INFO: Spider opened
2021-11-21 14:13:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 14:13:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 14:13:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baidu.com/> (referer: None)
2021-11-21 14:13:06 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 14:13:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 305,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 83298,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.523331,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 6, 13, 6, 36668),
 'httpcompression/response_bytes': 326135,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2021, 11, 21, 6, 13, 5, 513337)}
2021-11-21 14:13:06 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 14:17:12 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 14:17:12 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 14:17:12 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 14:17:12 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 3,
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders'],
 'USER_AGENT': 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 '
               'Safari/537.36'}
2021-11-21 14:17:13 [scrapy.extensions.telnet] INFO: Telnet Password: 75c0ece0cf672634
2021-11-21 14:17:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 14:17:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 14:17:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 14:17:13 [scrapy.middleware] INFO: Enabled item pipelines:
['Day1.pipelines.Day1Pipeline']
2021-11-21 14:17:13 [scrapy.core.engine] INFO: Spider opened
2021-11-21 14:17:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 14:17:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 14:17:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baidu.com/> (referer: None)
2021-11-21 14:17:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.baidu.com/> (referer: None)
Traceback (most recent call last):
  File "F:\Kernel\python\python3.9.9\lib\site-packages\twisted\internet\defer.py", line 858, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "F:\Kernel\python\python3.9.9\lib\site-packages\scrapy\spiders\__init__.py", line 90, in _parse
    return self.parse(response, **kwargs)
  File "F:\PyCharm\PyCharmProject\Reptile\Day1\Day1\spiders\baidu.py", line 23, in parse
    print(name+"的链接是"+src)
TypeError: can only concatenate list (not "str") to list
2021-11-21 14:17:14 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 14:17:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 305,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 83264,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.78439,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 6, 17, 14, 778969),
 'httpcompression/response_bytes': 326097,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2021, 11, 21, 6, 17, 13, 994579)}
2021-11-21 14:17:14 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 14:17:44 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 14:17:44 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 14:17:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 14:17:44 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 3,
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders'],
 'USER_AGENT': 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 '
               'Safari/537.36'}
2021-11-21 14:17:44 [scrapy.extensions.telnet] INFO: Telnet Password: 9733bedb2f77f2f4
2021-11-21 14:17:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 14:17:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 14:17:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 14:17:45 [scrapy.middleware] INFO: Enabled item pipelines:
['Day1.pipelines.Day1Pipeline']
2021-11-21 14:17:45 [scrapy.core.engine] INFO: Spider opened
2021-11-21 14:17:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 14:17:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 14:17:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baidu.com/> (referer: None)
2021-11-21 14:17:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.baidu.com/> (referer: None)
Traceback (most recent call last):
  File "F:\Kernel\python\python3.9.9\lib\site-packages\twisted\internet\defer.py", line 858, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "F:\Kernel\python\python3.9.9\lib\site-packages\scrapy\spiders\__init__.py", line 90, in _parse
    return self.parse(response, **kwargs)
  File "F:\PyCharm\PyCharmProject\Reptile\Day1\Day1\spiders\baidu.py", line 23, in parse
    print(name+"的链接是"+src)
TypeError: can only concatenate list (not "str") to list
2021-11-21 14:17:45 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 14:17:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 305,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 83107,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.584033,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 6, 17, 45, 794484),
 'httpcompression/response_bytes': 326115,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2021, 11, 21, 6, 17, 45, 210451)}
2021-11-21 14:17:45 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 14:17:58 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 14:17:58 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 14:17:58 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 14:17:58 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 3,
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders'],
 'USER_AGENT': 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 '
               'Safari/537.36'}
2021-11-21 14:17:58 [scrapy.extensions.telnet] INFO: Telnet Password: 1dc0fee2837a7518
2021-11-21 14:17:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 14:17:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 14:17:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 14:17:59 [scrapy.middleware] INFO: Enabled item pipelines:
['Day1.pipelines.Day1Pipeline']
2021-11-21 14:17:59 [scrapy.core.engine] INFO: Spider opened
2021-11-21 14:17:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 14:17:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 14:17:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baidu.com/> (referer: None)
2021-11-21 14:17:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.baidu.com/> (referer: None)
Traceback (most recent call last):
  File "F:\Kernel\python\python3.9.9\lib\site-packages\twisted\internet\defer.py", line 858, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "F:\Kernel\python\python3.9.9\lib\site-packages\scrapy\spiders\__init__.py", line 90, in _parse
    return self.parse(response, **kwargs)
  File "F:\PyCharm\PyCharmProject\Reptile\Day1\Day1\spiders\baidu.py", line 23, in parse
    print(name+"的链接是"+src)
TypeError: can only concatenate list (not "str") to list
2021-11-21 14:18:00 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 14:18:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 305,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 83115,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.570103,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 6, 18, 0, 49889),
 'httpcompression/response_bytes': 326133,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2021, 11, 21, 6, 17, 59, 479786)}
2021-11-21 14:18:00 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 14:18:37 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 14:18:37 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 14:18:37 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 14:18:37 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 3,
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders'],
 'USER_AGENT': 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 '
               'Safari/537.36'}
2021-11-21 14:18:37 [scrapy.extensions.telnet] INFO: Telnet Password: d0b6c77e6c14ca4f
2021-11-21 14:18:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 14:18:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 14:18:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 14:18:38 [scrapy.middleware] INFO: Enabled item pipelines:
['Day1.pipelines.Day1Pipeline']
2021-11-21 14:18:38 [scrapy.core.engine] INFO: Spider opened
2021-11-21 14:18:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 14:18:38 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 14:18:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baidu.com/> (referer: None)
2021-11-21 14:18:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.baidu.com/> (referer: None)
Traceback (most recent call last):
  File "F:\Kernel\python\python3.9.9\lib\site-packages\twisted\internet\defer.py", line 858, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "F:\Kernel\python\python3.9.9\lib\site-packages\scrapy\spiders\__init__.py", line 90, in _parse
    return self.parse(response, **kwargs)
  File "F:\PyCharm\PyCharmProject\Reptile\Day1\Day1\spiders\baidu.py", line 23, in parse
    print(name+"的链接是"+src)
TypeError: can only concatenate list (not "str") to list
2021-11-21 14:18:39 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 14:18:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 305,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 83125,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.639089,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 6, 18, 39, 261360),
 'httpcompression/response_bytes': 326145,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2021, 11, 21, 6, 18, 38, 622271)}
2021-11-21 14:18:39 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 14:20:41 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 14:20:41 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 14:20:41 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 14:20:41 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 3,
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders'],
 'USER_AGENT': 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 '
               'Safari/537.36'}
2021-11-21 14:20:41 [scrapy.extensions.telnet] INFO: Telnet Password: 0d40d8227fe2c7a5
2021-11-21 14:20:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 14:20:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 14:20:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 14:20:42 [scrapy.middleware] INFO: Enabled item pipelines:
['Day1.pipelines.Day1Pipeline']
2021-11-21 14:20:42 [scrapy.core.engine] INFO: Spider opened
2021-11-21 14:20:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 14:20:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 14:20:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baidu.com/> (referer: None)
2021-11-21 14:20:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.baidu.com/> (referer: None)
Traceback (most recent call last):
  File "F:\Kernel\python\python3.9.9\lib\site-packages\twisted\internet\defer.py", line 858, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "F:\Kernel\python\python3.9.9\lib\site-packages\scrapy\spiders\__init__.py", line 90, in _parse
    return self.parse(response, **kwargs)
  File "F:\PyCharm\PyCharmProject\Reptile\Day1\Day1\spiders\baidu.py", line 23, in parse
    print(name+"的链接是"+src)
TypeError: can only concatenate list (not "str") to list
2021-11-21 14:20:43 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 14:20:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 305,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 83112,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.467102,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 6, 20, 43, 75717),
 'httpcompression/response_bytes': 326092,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2021, 11, 21, 6, 20, 42, 608615)}
2021-11-21 14:20:43 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 14:22:52 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 14:22:52 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 14:22:52 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 14:22:52 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 3,
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders'],
 'USER_AGENT': 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 '
               'Safari/537.36'}
2021-11-21 14:22:52 [scrapy.extensions.telnet] INFO: Telnet Password: fdbddb77f5f74409
2021-11-21 14:22:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 14:22:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 14:22:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 14:22:53 [scrapy.middleware] INFO: Enabled item pipelines:
['Day1.pipelines.Day1Pipeline']
2021-11-21 14:22:53 [scrapy.core.engine] INFO: Spider opened
2021-11-21 14:22:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 14:22:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 14:22:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baidu.com/> (referer: None)
2021-11-21 14:22:53 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 14:22:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 305,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 83371,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.327739,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 6, 22, 53, 477730),
 'httpcompression/response_bytes': 326250,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2021, 11, 21, 6, 22, 53, 149991)}
2021-11-21 14:22:53 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 14:23:13 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 14:23:13 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 14:23:13 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 14:23:13 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 3,
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders'],
 'USER_AGENT': 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 '
               'Safari/537.36'}
2021-11-21 14:23:13 [scrapy.extensions.telnet] INFO: Telnet Password: f87989223529584a
2021-11-21 14:23:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 14:23:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 14:23:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 14:23:13 [scrapy.middleware] INFO: Enabled item pipelines:
['Day1.pipelines.Day1Pipeline']
2021-11-21 14:23:13 [scrapy.core.engine] INFO: Spider opened
2021-11-21 14:23:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 14:23:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 14:23:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baidu.com/> (referer: None)
2021-11-21 14:23:14 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 14:23:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 305,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 83084,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.297327,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 6, 23, 14, 196112),
 'httpcompression/response_bytes': 326069,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2021, 11, 21, 6, 23, 13, 898785)}
2021-11-21 14:23:14 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 14:26:17 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 14:26:17 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 14:26:17 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 14:26:17 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 3,
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders'],
 'USER_AGENT': 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 '
               'Safari/537.36'}
2021-11-21 14:26:17 [scrapy.extensions.telnet] INFO: Telnet Password: fef84062da95a70f
2021-11-21 14:26:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 14:26:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 14:26:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 14:26:18 [scrapy.middleware] INFO: Enabled item pipelines:
['Day1.pipelines.Day1Pipeline']
2021-11-21 14:26:18 [scrapy.core.engine] INFO: Spider opened
2021-11-21 14:26:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 14:26:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 14:26:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baidu.com/> (referer: None)
2021-11-21 14:26:18 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 14:26:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 305,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 83202,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.330132,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 6, 26, 18, 971298),
 'httpcompression/response_bytes': 326293,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2021, 11, 21, 6, 26, 18, 641166)}
2021-11-21 14:26:18 [scrapy.core.engine] INFO: Spider closed (finished)
2021-11-21 14:26:34 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Day1)
2021-11-21 14:26:34 [scrapy.utils.log] INFO: Versions: lxml 4.6.4.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
2021-11-21 14:26:34 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-11-21 14:26:34 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day1',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 3,
 'LOG_FILE': './logs.log',
 'NEWSPIDER_MODULE': 'Day1.spiders',
 'SPIDER_MODULES': ['Day1.spiders'],
 'USER_AGENT': 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 '
               'Safari/537.36'}
2021-11-21 14:26:34 [scrapy.extensions.telnet] INFO: Telnet Password: fc7b057f75e50323
2021-11-21 14:26:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-11-21 14:26:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-11-21 14:26:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-11-21 14:26:35 [scrapy.middleware] INFO: Enabled item pipelines:
['Day1.pipelines.Day1Pipeline']
2021-11-21 14:26:35 [scrapy.core.engine] INFO: Spider opened
2021-11-21 14:26:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-11-21 14:26:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-11-21 14:26:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baidu.com/> (referer: None)
2021-11-21 14:26:35 [scrapy.core.engine] INFO: Closing spider (finished)
2021-11-21 14:26:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 305,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 83339,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.326823,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 11, 21, 6, 26, 35, 832687),
 'httpcompression/response_bytes': 326247,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2021, 11, 21, 6, 26, 35, 505864)}
2021-11-21 14:26:35 [scrapy.core.engine] INFO: Spider closed (finished)
